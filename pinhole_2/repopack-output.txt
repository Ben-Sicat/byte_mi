This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repopack on: 2024-10-16T05:34:49.563Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repopack's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

For more information about Repopack, visit: https://github.com/yamadashy/repopack

================================================================
Repository Structure
================================================================
data/
  train/
    _annotations.coco.json
src/
  preprocessing/
    __init__.py
    image_scaling.py
    low_res_test.py
    noise_reduction.py
    preprocess.py
    test.py
  utils/
    __init__.py
    utils.py
    visualization.py
  __init__.py
.gitignore
readme.md
requirements.txt

================================================================
Repository Files
================================================================

================
File: data/train/_annotations.coco.json
================
{"info":{"year":"2024","version":"2","description":"Exported from roboflow.com","contributor":"","url":"https://public.roboflow.com/object-detection/undefined","date_created":"2024-10-14T17:41:31+00:00"},"licenses":[{"id":1,"url":"https://creativecommons.org/licenses/by/4.0/","name":"CC BY 4.0"}],"categories":[{"id":0,"name":"plate-paper","supercategory":"none"},{"id":1,"name":"paper","supercategory":"plate-paper"},{"id":2,"name":"paper-blue","supercategory":"plate-paper"},{"id":3,"name":"paper-yellow","supercategory":"plate-paper"},{"id":4,"name":"paper-yellow-bright","supercategory":"plate-paper"},{"id":5,"name":"plate","supercategory":"plate-paper"}],"images":[{"id":0,"license":1,"file_name":"Pairtwo_png.rf.e23749dcf6644b0a2e561634554a5009.jpg","height":480,"width":640,"date_captured":"2024-10-14T17:41:31+00:00"},{"id":1,"license":1,"file_name":"Pair3_png.rf.984a166a90eb4fb2fc2ea9a4e5a882f4.jpg","height":480,"width":640,"date_captured":"2024-10-14T17:41:31+00:00"},{"id":2,"license":1,"file_name":"Pair1_png.rf.9a41eaba847f2815f37ffd3e13598fc6.jpg","height":480,"width":640,"date_captured":"2024-10-14T17:41:31+00:00"}],"annotations":[{"id":0,"image_id":0,"category_id":5,"bbox":[154,67,344,341],"area":117304,"segmentation":[[332.2,67,309,67,270,75,237,90,215,105,199,120,176,151,161,184,154,216,154,254,159,280,171,312,191,343,217,369,252,391,293,405,322,408,354,406,388,397,420,381,439,367,462,343,481,313,494,276,498,243,494,201,485,173,473,150,454,124,430,102,396,82,375,74,338,67]],"iscrowd":0},{"id":1,"image_id":0,"category_id":3,"bbox":[201,155,128,107],"area":13696,"segmentation":[[263,155,251,164,238,162,232,166,223,165,218,168,210,185,208,212,201,222,203,229,219,248,251,255,260,262,288,260,294,257,298,248,310,236,314,233,323,233,322,223,329,220,328,215,319,206,302,198,301,189,287,186,289,168,286,163,270,155]],"iscrowd":0},{"id":2,"image_id":0,"category_id":4,"bbox":[223,259,72,59],"area":4248,"segmentation":[[243,259,231,265,223,280,223,289,235,309,253,311,263,318,271,310,280,292,291,293,295,290,294,276,288,270,288,263,273,262,268,267,245,259]],"iscrowd":0},{"id":3,"image_id":0,"category_id":1,"bbox":[346,144,132,113],"area":14916,"segmentation":[[413,144,398,148,374,166,364,165,360,179,352,186,346,201,348,217,352,224,379,222,372,237,375,248,380,252,394,253,402,257,418,255,430,247,451,240,451,227,454,223,478,207,476,198,455,183,456,169,449,166,438,168,438,158,429,147,415,144]],"iscrowd":0},{"id":4,"image_id":0,"category_id":2,"bbox":[362,259,65,69],"area":4485,"segmentation":[[396,259,368,272,364,276,362,291,372,308,390,320,399,318,398,324,404,328,414,302,426,293,427,289,417,265,413,261,405,262,402,259]],"iscrowd":0},{"id":5,"image_id":1,"category_id":5,"bbox":[164,69,349,345],"area":120405,"segmentation":[[343.25,69,301,72,276,79,249,92,221,112,200,134,179,169,169,196,164,228,166,271,174,299,186,325,207,355,237,382,260,396,288,407,324,414,364,413,400,404,426,392,453,373,480,344,495,319,509,281,513,250,509,205,500,177,484,147,463,121,434,97,407,83,380,74,349,69]],"iscrowd":0},{"id":6,"image_id":1,"category_id":1,"bbox":[359,147,134,115],"area":15410,"segmentation":[[433,147,413,150,387,169,378,167,373,173,373,181,361,195,359,214,363,227,379,228,386,224,394,226,385,240,386,250,393,256,419,262,463,246,467,243,465,237,467,230,477,220,493,210,492,203,484,194,471,187,471,172,465,169,453,171,451,158,438,147]],"iscrowd":0},{"id":7,"image_id":1,"category_id":2,"bbox":[373,263,67,71],"area":4757,"segmentation":[[410,263,381,276,376,282,377,285,373,295,380,303,383,313,396,319,402,325,411,325,412,332,418,334,418,329,424,322,425,313,428,307,440,296,440,292,436,285,431,270,427,266,421,266,414,263]],"iscrowd":0},{"id":8,"image_id":1,"category_id":3,"bbox":[212,159,129,108],"area":13932,"segmentation":[[273,159,263,168,248,166,244,169,233,169,228,172,220,192,218,219,212,224,212,231,229,253,261,259,271,267,300,265,309,258,311,252,323,239,327,236,334,236,333,229,335,226,341,225,341,221,331,210,313,202,314,195,312,192,306,193,298,189,300,187,300,170,294,164,282,159]],"iscrowd":0},{"id":9,"image_id":1,"category_id":4,"bbox":[233,263,74,60],"area":4440,"segmentation":[[254,263,241,272,233,289,234,294,242,304,244,312,246,314,255,316,265,316,275,323,277,319,282,316,290,297,293,296,301,298,305,296,307,286,304,278,299,275,301,270,298,267,286,266,275,269,260,265,258,263,255,264]],"iscrowd":0},{"id":10,"image_id":2,"category_id":5,"bbox":[163,87,332,333],"area":110556,"segmentation":[[331,87,301,89,269,98,240,113,221,127,195,155,179,182,169,207,163,246,164,273,172,308,189,344,208,368,228,386,260,405,293,416,324,420,353,418,386,410,415,396,443,375,470,343,481,322,490,299,495,270,495,236,489,205,477,176,457,146,428,119,399,102,363,90,336,87]],"iscrowd":0},{"id":11,"image_id":2,"category_id":3,"bbox":[211,174,122,101],"area":12322,"segmentation":[[284,174,272,180,261,175,236,177,223,199,220,220,211,230,226,258,249,263,262,275,293,275,310,261,313,254,326,254,327,247,333,244,325,230,310,223,313,212,301,205,301,184,285,174]],"iscrowd":0},{"id":12,"image_id":2,"category_id":4,"bbox":[221,267,69,57],"area":3933,"segmentation":[[243.5,267,234,269,221,288,229,312,246,316,256,324,268,314,276,302,287,304,290,291,285,285,286,279,258,276,255,270,249,267]],"iscrowd":0},{"id":13,"image_id":2,"category_id":1,"bbox":[351,190,127,109],"area":13843,"segmentation":[[418,190,400,196,391,206,374,204,370,212,354,226,351,235,353,252,362,255,376,254,380,257,371,267,372,276,378,287,400,299,420,294,441,293,444,291,444,281,449,276,478,261,477,251,461,235,462,224,458,218,447,220,448,207,442,197,421,190]],"iscrowd":0},{"id":14,"image_id":2,"category_id":2,"bbox":[350,286,60,63],"area":3780,"segmentation":[[367,286,352,298,353,310,350,314,359,335,366,340,363,343,364,349,377,344,385,336,404,333,410,314,408,301,396,301,386,292,369,286]],"iscrowd":0}]}

================
File: src/preprocessing/__init__.py
================
from .image_scaling import upscale_depth, align_segmentation_mask
from .noise_reduction import reduce_depth_noise

================
File: src/preprocessing/image_scaling.py
================
import cv2
import numpy as np

""" 
    The goal of this file is to match the resolution of the RGB Image
    since the RGB Depth Image is in a lower resolution
"""

def upscale_depth(rgbd_image, target_shape):
    """
        
        args:
        rgbd_image (numpy.ndarray): RGBD image with depth as the 4th channel
        target_shape (tuple): Desired output shape (height, width)
        
        returns:
        numpy.ndarray: RGBD image with upscaled depth
    
    """
    if rgbd_image.shape[2] != 4:
        raise ValueError("Expected RGBD image with 4 channels")
    
    h, w = rgbd_image.shape[:2]
    target_h, target_w = target_shape

    # Calculate scaling factor while maintaining aspect ratio
    scale = min(target_w / w, target_h / h)
    new_w, new_h = int(w * scale), int(h * scale)

    # Resize RGB and depth channels separately
    rgb_resized = cv2.resize(rgbd_image[:,:,:3], (new_w, new_h), interpolation=cv2.INTER_LINEAR)
    depth_resized = cv2.resize(rgbd_image[:,:,3], (new_w, new_h), interpolation=cv2.INTER_NEAREST)

    # Create a new RGBD image with the target shape
    upscaled_rgbd = np.zeros((*target_shape, 4), dtype=rgbd_image.dtype)
    
    # Calculate padding
    pad_w = (target_w - new_w) // 2
    pad_h = (target_h - new_h) // 2

    # Place the resized image in the center
    upscaled_rgbd[pad_h:pad_h+new_h, pad_w:pad_w+new_w, :3] = rgb_resized
    upscaled_rgbd[pad_h:pad_h+new_h, pad_w:pad_w+new_w, 3] = depth_resized

    return upscaled_rgbd
def align_segmentation_mask(mask, rgbd_shape):

    """
        args:
        mask (numpy.ndarray): Segmentation mask
        rgbd_shape (tuple): shape of rgbd image


        return:
        numpy_ndarry: Aligned Segmentation mask
    """
    
    if mask.shape[:2] != rgbd_shape[:2]:
        return cv2.resize(mask,(rgbd_shape[1],rgbd_shape[0]), interpolation=cv2.INTER_NEAREST)


    return mask

================
File: src/preprocessing/low_res_test.py
================
# src/preprocessing/test_low_res_rgbd.py

import os
import numpy as np
import cv2
import matplotlib.pyplot as plt
from src.utils.utils import load_rgbd_image, get_corresponding_rgbd_filename
from src.preprocessing.noise_reduction import reduce_depth_noise

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..')))
def visualize_rgbd(rgbd_image, title):
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))
    
    # Visualize RGB
    ax1.imshow(rgbd_image[:,:,:3])
    ax1.set_title("RGB")
    ax1.axis('off')
    
    # Visualize Depth
    depth_vis = ax2.imshow(rgbd_image[:,:,3], cmap='jet')
    ax2.set_title("Depth")
    ax2.axis('off')
    plt.colorbar(depth_vis, ax=ax2, label='Depth')
    
    plt.suptitle(title)
    plt.tight_layout()
    return fig

def process_low_res_rgbd(rgb_filename, output_dir):
    # Get corresponding RGBD filename
    rgbd_filename = get_corresponding_rgbd_filename(rgb_filename)
    if rgbd_filename is None:
        raise ValueError(f"No corresponding RGBD filename found for {rgb_filename}")

    # Load low-resolution RGBD image
    data_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', 'data'))
    image_input_dir = os.path.join(data_dir, 'image_input')
    rgbd_path = os.path.join(image_input_dir, rgbd_filename)
    original_rgbd = load_rgbd_image(rgbd_path)

    print(f"Loaded RGBD image shape: {original_rgbd.shape}")
    print(f"Depth channel min: {original_rgbd[:,:,3].min()}, max: {original_rgbd[:,:,3].max()}")
    print(f"Unique depth values: {np.unique(original_rgbd[:,:,3])}")

    # Visualize original RGBD
    fig_original = visualize_rgbd(original_rgbd, "Original Low-res RGBD")
    fig_original.savefig(os.path.join(output_dir, f"{os.path.splitext(rgbd_filename)[0]}_original.png"))
    plt.close(fig_original)

    # Apply noise reduction to depth channel
    depth = original_rgbd[:,:,3].astype(np.float32)
    noise_reduced_depth = reduce_depth_noise(depth)

    print(f"Noise reduced depth min: {noise_reduced_depth.min()}, max: {noise_reduced_depth.max()}")

    # Create noise-reduced RGBD image
    noise_reduced_rgbd = original_rgbd.copy()
    noise_reduced_rgbd[:,:,3] = noise_reduced_depth

    # Visualize noise-reduced RGBD
    fig_reduced = visualize_rgbd(noise_reduced_rgbd, "Noise-reduced Low-res RGBD")
    fig_reduced.savefig(os.path.join(output_dir, f"{os.path.splitext(rgbd_filename)[0]}_noise_reduced.png"))
    plt.close(fig_reduced)

    return original_rgbd, noise_reduced_rgbd

def main():
    output_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', 'output', 'low_res_test'))
    os.makedirs(output_dir, exist_ok=True)

    rgb_filenames = [
        'Pair1_png.rf.9a41eaba847f2815f37ffd3e13598fc6.jpg',
        'Pairtwo_png.rf.e23749dcf6644b0a2e561634554a5009.jpg',
        'Pair3_png.rf.984a166a90eb4fb2fc2ea9a4e5a882f4.jpg'
    ]

    for rgb_filename in rgb_filenames:
        print(f"Processing {rgb_filename}")
        original_rgbd, noise_reduced_rgbd = process_low_res_rgbd(rgb_filename, output_dir)
        print("---")

if __name__ == "__main__":
    main()

================
File: src/preprocessing/noise_reduction.py
================
import cv2
import numpy as np


def reduce_depth_noise(depth_image, method='bilateral'):
    """
        args:
        depth_image (numpy.ndarray): depth depth_image
        method (str) : noise reduction method ('bilateral' or 'median')

        return:
        numpy.ndarray: Noise reduced dpeth depth_image

    """
    print(f"Noise reduction input depth min: {depth_image.min()}, max: {depth_image.max()}")
    
    if method == 'bilateral':
        result = cv2.bilateralFilter(depth_image, 9, 75, 75)
    elif method == 'median':
        result = cv2.medianBlur(depth_image, 5)
    else:
        raise ValueError('Unsupported noise reduction method')
    
    print(f"Noise reduction output depth min: {result.min()}, max: {result.max()}")
    return result

================
File: src/preprocessing/preprocess.py
================
import os
import numpy as np
import cv2
import matplotlib.pyplot as plt
from src.utils.utils import (
    load_rgbd_image,
    load_coco_data,
    create_segmentation_mask,
    get_corresponding_rgbd_filename,
    ensure_directory_exists
)
from src.preprocessing.image_scaling import upscale_depth, align_segmentation_mask
from src.preprocessing.noise_reduction import reduce_depth_noise
from src.utils.visualization import visualize_preprocessing_steps, visualize_depth

class PreprocessingPipeline:
    def __init__(self, data_dir, output_dir):
        self.data_dir = data_dir
        self.output_dir = output_dir
        self.image_input_dir = os.path.join(data_dir, 'image_input')
        self.train_dir = os.path.join(data_dir, 'train')
        self.segmentation_file = os.path.join(data_dir, 'train', '_annotations.coco.json')
        
        # Create output directories
        ensure_directory_exists(output_dir)
        self.upscaled_dir = os.path.join(output_dir, 'upscaled')
        ensure_directory_exists(self.upscaled_dir)

    def process_image(self, rgb_filename, image_id):
        try:
            # Load high-resolution RGB image
            rgb_path = os.path.join(self.train_dir, rgb_filename)
            rgb_image = cv2.imread(rgb_path)
            if rgb_image is None:
                raise FileNotFoundError(f"Could not load RGB image at {rgb_path}")
            rgb_image = cv2.cvtColor(rgb_image, cv2.COLOR_BGR2RGB)
            print(f"Loaded RGB image shape: {rgb_image.shape}")

            # Get corresponding RGBD filename
            rgbd_filename = get_corresponding_rgbd_filename(rgb_filename)
            if rgbd_filename is None:
                raise ValueError(f"No corresponding RGBD filename found for {rgb_filename}")

            # Load low-resolution RGBD image
            rgbd_path = os.path.join(self.image_input_dir, rgbd_filename)
            original_rgbd = load_rgbd_image(rgbd_path)
            print(f"Loaded RGBD image shape: {original_rgbd.shape}")
            print(f"Loaded RGBD depth min: {original_rgbd[:,:,3].min()}, max: {original_rgbd[:,:,3].max()}")

            # Upscale RGBD to match RGB resolution
            upscaled_rgbd = upscale_depth(original_rgbd, (rgb_image.shape[0], rgb_image.shape[1]))
            print(f"Upscaled RGBD shape: {upscaled_rgbd.shape}")
            print(f"Upscaled RGBD depth min: {upscaled_rgbd[:,:,3].min()}, max: {upscaled_rgbd[:,:,3].max()}")

            # Load and create segmentation mask
            coco_data = load_coco_data(self.segmentation_file)
            mask = create_segmentation_mask(image_id, coco_data)
            print(f"Created segmentation mask shape: {mask.shape}")

            # Ensure mask shape matches RGB image shape
            mask = align_segmentation_mask(mask, rgb_image.shape[:2])
            print(f"Aligned segmentation mask shape: {mask.shape}")

            # Reduce noise in depth
            original_depth = original_rgbd[:,:,3].astype(np.float32)
            noise_reduced_depth = reduce_depth_noise(original_depth)
            upscaled_noise_reduced_depth = cv2.resize(noise_reduced_depth, (rgb_image.shape[1], rgb_image.shape[0]), interpolation=cv2.INTER_LINEAR)
            print(f"Noise reduced depth min: {upscaled_noise_reduced_depth.min()}, max: {upscaled_noise_reduced_depth.max()}")

            # Save upscaled RGBD image as numpy array (full color + depth)
            upscaled_rgbd_path = os.path.join(self.upscaled_dir, f'{os.path.splitext(rgb_filename)[0]}_upscaled_rgbd.npy')
            np.save(upscaled_rgbd_path, upscaled_rgbd)
            print(f"Saved upscaled RGBD to: {upscaled_rgbd_path}")

            upscaled_rgbd_vis_path = os.path.join(self.upscaled_dir, f'{os.path.splitext(rgb_filename)[0]}_upscaled_rgbd_vis.png')
            rgbd_vis = upscaled_rgbd[:,:,:3].astype(np.uint8)  # Use only the RGB channels for visualization
            cv2.imwrite(upscaled_rgbd_vis_path, cv2.cvtColor(rgbd_vis, cv2.COLOR_RGB2BGR))
            print(f"Saved upscaled RGBD visualization to: {upscaled_rgbd_vis_path}")

            # Visualize results
            visualize_preprocessing_steps(rgb_image, original_rgbd, upscaled_rgbd, mask, noise_reduced_depth, self.output_dir)
            print(f"Saved preprocessing visualization to: {self.output_dir}")

            return upscaled_rgbd, mask


        except Exception as e:
            print(f"Error processing image {rgb_filename}: {str(e)}")
            raise

    def run(self):
        rgb_filenames = [
            'Pair1_png.rf.9a41eaba847f2815f37ffd3e13598fc6.jpg',
            'Pairtwo_png.rf.e23749dcf6644b0a2e561634554a5009.jpg',
            'Pair3_png.rf.984a166a90eb4fb2fc2ea9a4e5a882f4.jpg'
        ]
        image_ids = [2, 0, 1]  # Corresponding image IDs in the COCO dataset

        for rgb_filename, image_id in zip(rgb_filenames, image_ids):
            print(f"Processing {rgb_filename}")
            upscaled_rgbd, mask = self.process_image(rgb_filename, image_id)
            print(f"Processed {rgb_filename}. Upscaled RGBD shape: {upscaled_rgbd.shape}, Mask shape: {mask.shape}")
            print(f"Saved upscaled RGBD and visualizations to {self.upscaled_dir}")
            print("---")

================
File: src/preprocessing/test.py
================
# src/preprocessing/test.py

import os
import sys
import numpy as np
import cv2

# Add the project root directory to the Python path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..')))

from src.preprocessing.preprocess import PreprocessingPipeline
from src.utils.utils import load_rgbd_image, create_segmentation_mask, load_coco_data

def test_load_rgbd_image(pipeline):
    rgbd_filename = 'Pairone.png'
    rgbd_image = load_rgbd_image(os.path.join(pipeline.image_input_dir, rgbd_filename))
    assert rgbd_image.shape[2] == 4, f"Expected 4-channel RGBD image, got {rgbd_image.shape[2]} channels"
    print(f"RGBD image shape: {rgbd_image.shape}")
    print(f"RGB min: {rgbd_image[:,:,:3].min()}, max: {rgbd_image[:,:,:3].max()}")
    print(f"Depth min: {rgbd_image[:,:,3].min()}, max: {rgbd_image[:,:,3].max()}")
    print(f"Unique depth values: {np.unique(rgbd_image[:,:,3])}")

def test_create_segmentation_mask(pipeline):
    coco_data = load_coco_data(pipeline.segmentation_file)
    mask = create_segmentation_mask(2, coco_data)  # Using image_id 2 for 'Pair1_png'
    assert mask.shape == (480, 640), f"Expected mask shape (480, 640), got {mask.shape}"
    print(f"Segmentation mask shape: {mask.shape}")
    print(f"Unique mask values: {np.unique(mask)}")

def test_preprocessing_pipeline():
    data_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', 'data'))
    output_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', 'output'))
    pipeline = PreprocessingPipeline(data_dir, output_dir)

    print("Testing load_rgbd_image function:")
    test_load_rgbd_image(pipeline)

    print("\nTesting create_segmentation_mask function:")
    test_create_segmentation_mask(pipeline)

    print("\nRunning full preprocessing pipeline:")
    pipeline.run()

    # Check if output files are created
    rgb_filenames = [
        'Pair1_png.rf.9a41eaba847f2815f37ffd3e13598fc6.jpg',
        'Pairtwo_png.rf.e23749dcf6644b0a2e561634554a5009.jpg',
        'Pair3_png.rf.984a166a90eb4fb2fc2ea9a4e5a882f4.jpg'
    ]
    
# In the test_preprocessing_pipeline function
    for rgb_filename in rgb_filenames:
        upscaled_rgbd_path = os.path.join(output_dir, 'upscaled', f'{os.path.splitext(rgb_filename)[0]}_upscaled_rgbd.npy')
        assert os.path.exists(upscaled_rgbd_path), f"Upscaled RGBD file not found: {upscaled_rgbd_path}"
        
    visualization_path = os.path.join(output_dir, 'preprocessing_visualization.png')
    assert os.path.exists(visualization_path), f"Visualization file not found: {visualization_path}"

    print("All tests passed successfully!")

if __name__ == "__main__":
    test_preprocessing_pipeline()

================
File: src/utils/__init__.py
================
from .visualization import visualize_preprocessing_steps
from .utils import (
    load_rgbd_image,
    load_coco_data,
    create_segmentation_mask,
    get_corresponding_rgbd_filename,
    ensure_directory_exists,
    align_segmentation_mask
)

================
File: src/utils/utils.py
================
# src/utils/utils.py

import os
import json
import cv2
import numpy as np

def load_rgbd_image(image_path):
    img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)
    if img is None:
        raise FileNotFoundError(f"Could not load image at {image_path}")
    if img.shape[2] != 4:
        raise ValueError(f"Expected 4-channel RGBD image, got {img.shape[2]} channels")
    
    print(f"Loaded RGBD image shape: {img.shape}")
    print(f"Depth channel min: {img[:,:,3].min()}, max: {img[:,:,3].max()}")
    print(f"Unique depth values: {np.unique(img[:,:,3])}")
    
    return img

def load_coco_data(json_file):
    with open(json_file, 'r') as f:
        return json.load(f)

def create_segmentation_mask(image_id, coco_data):
    image_info = next(img for img in coco_data['images'] if img['id'] == image_id)
    mask = np.zeros((image_info['height'], image_info['width']), dtype=np.uint8)
    
    annotations = [ann for ann in coco_data['annotations'] if ann['image_id'] == image_id]
    
    for ann in annotations:
        category_id = ann['category_id']
        for segmentation in ann['segmentation']:
            pts = np.array(segmentation).reshape((-1, 2)).astype(np.int32)
            cv2.fillPoly(mask, [pts], color=category_id)

    return mask

def get_corresponding_rgbd_filename(rgb_filename):
    mapping = {
        'Pair1_png.rf.9a41eaba847f2815f37ffd3e13598fc6.jpg': 'Pairone.png',
        'Pairtwo_png.rf.e23749dcf6644b0a2e561634554a5009.jpg': 'Pairtwo.png',
        'Pair3_png.rf.984a166a90eb4fb2fc2ea9a4e5a882f4.jpg': 'Pairthree.png'
    }
    return mapping.get(rgb_filename)

def ensure_directory_exists(directory):
    """Create directory if it doesn't exist."""
    os.makedirs(directory, exist_ok=True)

def align_segmentation_mask(mask, target_shape):
    """Resize segmentation mask to match target shape."""
    if mask.shape[:2] != target_shape:
        return cv2.resize(mask, (target_shape[1], target_shape[0]), interpolation=cv2.INTER_NEAREST)
    return mask

def save_depth_image(depth_data, output_path, as_uint8=True):
    """
    Save depth data as an image file.
    
    Args:
    depth_data (numpy.ndarray): 2D array of depth values
    output_path (str): Path to save the image
    as_uint8 (bool): If True, convert depth to uint8 before saving
    """
    if as_uint8:
        # Normalize depth to 0-255 range
        depth_min = np.min(depth_data)
        depth_max = np.max(depth_data)
        if depth_min != depth_max:
            depth_normalized = ((depth_data - depth_min) / (depth_max - depth_min) * 255).astype(np.uint8)
        else:
            depth_normalized = np.zeros_like(depth_data, dtype=np.uint8)
    else:
        depth_normalized = depth_data

    cv2.imwrite(output_path, depth_normalized)

def load_depth_image(input_path, as_float=True):
    """
    Load a depth image file.
    
    Args:
    input_path (str): Path to the depth image file
    as_float (bool): If True, convert depth to float32
    
    Returns:
    numpy.ndarray: 2D array of depth values
    """
    depth_image = cv2.imread(input_path, cv2.IMREAD_UNCHANGED)
    
    if depth_image is None:
        raise FileNotFoundError(f"Could not load depth image at {input_path}")
    
    if as_float:
        depth_image = depth_image.astype(np.float32) / 255.0
    
    return depth_image

def visualize_depth(depth_image, output_path):
    """
    Create a color visualization of a depth image and save it.
    
    Args:
    depth_image (numpy.ndarray): 2D array of depth values
    output_path (str): Path to save the visualization
    """
    plt.figure(figsize=(10, 8))
    plt.imshow(depth_image, cmap='viridis')
    plt.colorbar(label='Depth')
    plt.title('Depth Visualization')
    plt.axis('off')
    plt.savefig(output_path)
    plt.close()

================
File: src/utils/visualization.py
================
# src/utils/visualization.py

import matplotlib
matplotlib.use('Agg')  # Set the backend to Agg
import matplotlib.pyplot as plt
import numpy as np
import cv2
import os

def visualize_depth(depth_image):
    depth_min, depth_max = np.min(depth_image), np.max(depth_image)
    if depth_min != depth_max:
        normalized_depth = (depth_image - depth_min) / (depth_max - depth_min)
    else:
        normalized_depth = np.zeros_like(depth_image)
    return plt.cm.viridis(normalized_depth)

def visualize_preprocessing_steps(rgb_image, original_rgbd, upscaled_rgbd, segmentation_mask, noise_reduced_depth, output_dir):
    fig, axs = plt.subplots(3, 3, figsize=(15, 15))
    fig.suptitle('Preprocessing Pipeline Visualization', fontsize=16)

    # High-res RGB
    axs[0, 0].imshow(rgb_image)
    axs[0, 0].set_title('High-res RGB')
    axs[0, 0].axis('off')

    # Original low-res RGBD (color part)
    axs[0, 1].imshow(original_rgbd[:,:,:3].astype(np.uint8))
    axs[0, 1].set_title('Original low-res RGBD (color)')
    axs[0, 1].axis('off')

    # Segmentation Mask
    axs[0, 2].imshow(segmentation_mask, cmap='tab10')
    axs[0, 2].set_title('Segmentation Mask')
    axs[0, 2].axis('off')

    # Upscaled RGBD (color part)
    axs[1, 0].imshow(upscaled_rgbd[:,:,:3].astype(np.uint8))
    axs[1, 0].set_title('Upscaled RGBD (color)')
    axs[1, 0].axis('off')

    # Upscaled Depth
    depth_vis = visualize_depth(upscaled_rgbd[:,:,3])
    axs[1, 1].imshow(depth_vis)
    axs[1, 1].set_title(f'Upscaled Depth (min: {upscaled_rgbd[:,:,3].min():.2f}, max: {upscaled_rgbd[:,:,3].max():.2f})')
    axs[1, 1].axis('off')

    # Upscaled RGBD (false color)
    upscaled_rgbd_vis = np.copy(upscaled_rgbd[:,:,:3])
    upscaled_rgbd_vis[:,:,2] = upscaled_rgbd[:,:,3]  # Replace blue channel with depth
    axs[1, 2].imshow(upscaled_rgbd_vis.astype(np.uint8))
    axs[1, 2].set_title('Upscaled RGBD (false color)')
    axs[1, 2].axis('off')

    # Original Depth
    original_depth_vis = visualize_depth(original_rgbd[:,:,3])
    axs[2, 0].imshow(original_depth_vis)
    axs[2, 0].set_title(f'Original Depth (min: {original_rgbd[:,:,3].min():.2f}, max: {original_rgbd[:,:,3].max():.2f})')
    axs[2, 0].axis('off')

    # Noise Reduced Depth
    noise_reduced_depth_vis = visualize_depth(noise_reduced_depth)
    axs[2, 1].imshow(noise_reduced_depth_vis)
    axs[2, 1].set_title(f'Noise Reduced Depth (min: {noise_reduced_depth.min():.2f}, max: {noise_reduced_depth.max():.2f})')
    axs[2, 1].axis('off')

    # Overlay segmentation on upscaled RGBD
    overlay = overlay_segmentation_on_rgbd(upscaled_rgbd, segmentation_mask)
    axs[2, 2].imshow(overlay[:,:,:3].astype(np.uint8))
    axs[2, 2].set_title('Segmentation on Upscaled RGBD')
    axs[2, 2].axis('off')

    plt.tight_layout()
    
    # Save the figure
    output_path = os.path.join(output_dir, 'preprocessing_visualization.png')
    plt.savefig(output_path)
    plt.close(fig)
    print(f"Visualization saved to: {output_path}")

def overlay_segmentation_on_rgbd(upscaled_rgbd, segmentation_mask):
    # Resize segmentation mask to match upscaled RGBD
    resized_mask = cv2.resize(segmentation_mask, (upscaled_rgbd.shape[1], upscaled_rgbd.shape[0]), 
                              interpolation=cv2.INTER_NEAREST)
    
    # Create a color map for segmentation
    cmap = plt.get_cmap('tab10')
    seg_colors = cmap(resized_mask / np.max(resized_mask))[:,:,:3]
    
    # Create a blended image
    alpha = 0.3  # Adjust this for segmentation transparency
    blended = upscaled_rgbd[:,:,:3] * (1-alpha) + seg_colors * alpha * 255
    
    # Add the depth channel back
    return np.dstack((blended, upscaled_rgbd[:,:,3]))

================
File: src/__init__.py
================
from . import preprocessing

================
File: .gitignore
================
venv/

================
File: readme.md
================
# OKAY BITCHES TIME TO DEV THIS SHIT SORRY I'M JUST DOING THIS NOW
## date is October 14, 2023

so now first I'll be trying to develop the loading of data
- get the segmentation points 
- get the RGB depth image
  - needs to be upscaled so that the segmentation points match
- overlay the segmentation points to the depth image

### Cloud Plotting
- do the cloud Plotting

-- refer to the notes --


1. Problem Overview:
   We're working on estimating the volume of objects (in this case, crumpled paper balls) on a plate using a combination of RGB and depth imaging. The challenge is that we have a high-resolution RGB image but only a noisy, low-resolution depth image.

2. Data Sources:
   - High-resolution RGB image of a plate with crumpled paper balls
   - Low-resolution, noisy depth image of the same scene

3. Proposed Approach:
   a) Segmentation:
      - Use Mask R-CNN (or another segmentation method) on the RGB image to precisely identify the plate and paper balls.
   
   b) Depth Image Processing:
      - Scale the low-resolution depth image to match the RGB image's resolution.
      - Apply noise reduction techniques to improve depth data quality.
   
   c) Data Fusion:
      - Overlay the segmentation masks from the RGB image onto the scaled depth image.
      - Extract depth values only for pixels corresponding to the segmented objects.

   d) 3D Reconstruction:
      - Use the camera's intrinsic parameters (from the pinhole camera model) to convert 2D pixel coordinates and depth values into 3D points.
      - The known plate diameter serves as a reference for real-world scaling.

   e) Volume Estimation:
      - Use methods like Convex Hull or more advanced techniques to estimate the volume of the reconstructed 3D points for each paper ball.

4. Key Considerations:
   - Careful alignment of RGB and depth data
   - Handling noise and inaccuracies in the depth data
   - Accounting for potential loss of fine details due to initial low depth resolution
   - Calibration and real-world scaling using the plate as a reference object

5. Potential Enhancements:
   - Multi-view analysis if multiple images are available
   - Implementing more sophisticated depth refinement techniques
   - Exploring machine learning approaches for improved depth estimation

6. Validation:
   - Compare results with ground truth volumes (if available)
   - Analyze performance across different object shapes and sizes

================
File: requirements.txt
================
numpy==2.1.2
opencv-python==4.10.0.84
pandas==2.2.3
python-dateutil==2.9.0.post0
pytz==2024.2
six==1.16.0
tzdata==2024.2
